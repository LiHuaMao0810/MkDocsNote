# 贝叶斯决策论



## 贝叶斯决策论核心

根据PPT的内容，**贝叶斯决策论（Bayesian Decision Theory）** 的核心在于：**在不确定性的情况下，如何利用概率来做出“最优”的选择。**

它的逻辑结构非常严密，我们可以分三个层次来理解并记笔记：

### 1. 核心公式：从“因”推“果”

在分类任务中，我们已知的是**特征 $x$**（比如鱼的长度），想知道的是它属于哪个**类别 $\omega_i$**。贝叶斯公式把这个问题转化成了三个已知项：

$$P(\omega_i | x) = \frac{P(x | \omega_i) \cdot P(\omega_i)}{P(x)}$$

- **后验概率 $P(\omega_i | x)$（目标）：** 看到特征 $x$ 后，它属于 $\omega_i$ 类的概率。这是我们决策的依据。
- **先验概率 $P(\omega_i)$（经验）：** 在没看到数据之前，根据常识或历史数据，某个类别出现的概率。
- **似然 $P(x | \omega_i)$（数据表现）：** 在这个类别中，出现特征 $x$ 的概率。
- **证据 $P(x)$（归一化）：** 所有类别中出现 $x$ 的总概率，通常作为分母，在比较不同类别时可以忽略。

**结论：** 贝叶斯决策就是比较各个类别的后验概率，哪个大就选哪个。

> [!example]
>
> 高中经常有这种概率题，小明有0.2概率骑车上学 0.8概率乘公交上学。如果小明骑车有0.6概率迟到，乘公交有0.4概率迟到，然后已知小明迟到的情况下，判断他更有可能是怎么来学校的？

---

**决策规则：三种判断标准**

PPT中提到了我们在做决定时可能采取的不同激进程度：

- 基于先验的决策 (Prior only)：

  如果你对当前的鱼一无所知，你只能赌概率最大的那种。比如：这片海里90%是鲈鱼，那抓到一条鱼你直接猜它是鲈鱼。

  - *缺点：* 完全忽略了当前的具体特征。

- 最大似然决策 (ML - Maximum Likelihood)：

  完全看数据。哪种鱼长成这样的概率最高，就选哪种。

  - *逻辑：* 比较 $P(x|\omega_1)$ 和 $P(x|\omega_2)$。

- 贝叶斯决策 (Bayes Decision - 后验最大化)：

  综合“经验”和“数据”。即使数据看起来像三文鱼，但如果三文鱼极其罕见（先验极低），模型依然可能倾向于判断它是鲈鱼。

  - *逻辑：* 比较 $P(x|\omega_i)P(\omega_i)$。

  > [!example]
  >
  > **比较后验概率 $P(\omega_i|x)$ 实际上等同于比较 $P(x|\omega_i)P(\omega_i)$** 。
  >
  > $$P(\omega_i|x) = \frac{P(x|\omega_i)P(\omega_i)}{P(x)}$$
  >
  > 在前面的例子中：
  >
  > - **$x$（观测到的特征）：** 小明迟到了。
  > - **$\omega_1$（类别1）：** 骑车。
  > - **$\omega_2$（类别2）：** 乘公交。
  >
  > 你要判断的是：已知迟到，骑车概率大 $P(\omega_1|迟到)$ 还是坐车概率大 $P(\omega_2|迟到)$？
  >
  > 在比较这两个分数时，分母 $P(迟到)$ 是完全一样的。既然分母相同，我们只需要比较分子部分，即 “似然 $\times$ 先验”：
  >
  > - **骑车且迟到：** $P(迟到|骑车) \times P(骑车) = 0.6 \times 0.2 = 0.12$
  > - **坐车且迟到：** $P(迟到|坐车) \times P(坐车) = 0.4 \times 0.8 = 0.32$
  >
  > 由于 $0.32 > 0.12$，我们判定他更有可能是坐公交来的。
  >
  > ------
  >
  > 把这个例子填入 PPT 的知识框架里：
  >
  > - **先验概率 (Prior) $P(\omega_i)$：** 还没看是否迟到前，小明平时的交通习惯（0.2骑车，0.8公交）。
  > - **似然 (Likelihood) $P(x|\omega_i)$：** 在某种交通方式下，迟到的概率（0.6 和 0.4）。
  > - **后验概率 (Posterior) $P(\omega_i|x)$：** 发生迟到后，倒推交通方式的概率。
  > - **证据 (Evidence) $P(x)$：** 小明总的迟到概率，计算方式为 $\sum P(x|\omega_i)P(\omega_i) = 0.12 + 0.32 = 0.44$。
  >
  > ---
  >
  > **特殊情况：什么时候只看似然？**
  >
  > 如果小明骑车和坐公交的概率是一样的（等先验，$P(\omega_1) = P(\omega_2)$），那么决策规则就退化成了最大似然决策 (Maximum Likelihood Decision) 。
  >
  > 此时你只需要看哪个交通方式更容易导致迟到（0.6 > 0.4），就会判定他是骑车来的。
  >
  > 但因为在这个例子中，小明坐公交的“先验”太大了（0.8），所以即便公交不容易迟到，最终的“后验”还是坐公交更高。

------

**核心目标：最小化错误率 (Minimizing Error)**

PPT 强调了为什么要用后验概率：因为**最大化后验概率等同于最小化分类错误率**。

- **决策边界 (Decision Boundary)：** 在特征空间中，必然存在一个点，使得 $P(\omega_1|x) = P(\omega_2|x)$。这个点就是分类的分界线。
- **错误率的组成：** 错误发生在“本来是A类，但被划到了B类区域”的地方。贝叶斯决策通过精准划分边界，确保这些错误区域的面积加起来最小。

------



## 一般化与风险函数

在贝叶斯决策论中，引入**风险函数（Risk Function）**是为了解决一个现实问题：**不同的错误，代价是不一样的。**

在之前的“小明迟到”或者“鱼类分类”中，我们默认只要猜对了就行，猜错的后果都一样。但在实际应用中，比如“判断肿瘤良性还是恶性”，把恶性错判为良性（漏诊）的后果，显然比把良性错判为恶性（误诊）要严重得多。

以下是关于一般化风险函数的笔记内容：

1. 决策动作与损失函数

在一般化的模型中，我们不仅有类别（状态 $\omega_j$），还有我们的决策动作（$\alpha_i$）。

为了衡量决策的好坏，我们定义了损失函数 $\lambda(\alpha_i | \omega_j)$。它表示：当事物的真实状态其实是 $\omega_j$ 时，如果我们采取了动作 $\alpha_i$，我们要付出多大的代价。

例如，在医疗诊断中：

- $\lambda(判为良性 | 实际恶性)$ 的数值会设得非常大（代价极高）。
- $\lambda(判为恶性 | 实际良性)$ 的数值虽然也是错的，但设得相对较小。
- 条件风险 (Conditional Risk)

当我们观测到特征 $x$ 时，如果采取动作 $\alpha_i$，可能会面临风险。因为我们不确定 $x$ 到底属于哪个类，所以要对所有可能的真实类别求一个“加权平均代价”。

这个加权平均后的代价就叫条件风险 $R(\alpha_i | x)$，计算公式为：

$$R(\alpha_i | x) = \sum_{j=1}^{c} \lambda(\alpha_i | \omega_j) P(\omega_j | x)$$

简单来说，就是：（做动作 i 的代价）= $\sum$（真实情况是 j 的代价 $\times$ 真实情况是 j 的后验概率）。

3. 贝叶斯风险决策准则

我们的目标非常明确：对于给定的观测值 $x$，计算每一种可能动作的条件风险，然后选择那个能让风险最小化的动作。

这就是最小风险贝叶斯决策。

4. 特殊情况：最小错误率分类

PPT 中提到了一个很重要的结论：如果我们把损失函数定义为 "0-1 损失"（即：猜对了损失为 0，猜错了无论错成什么样损失都是 1），那么：

- 最小化风险就等同于最大化后验概率 $P(\omega_i | x)$。

  这就是你之前理解的那个“比谁概率大”的逻辑。可以说，“最小错误率”只是“最小风险”在特定权重下的一种特例。

- 决策边界的移动

引入风险函数后，特征空间里的决策边界会发生移动。

比如在小明的例子中，如果“骑车迟到”会被开除（代价极大），而“坐公交迟到”只是被老师说两句，那么即使算出来骑车迟到的概率更低，为了规避被开除的风险，模型可能依然会倾向于判断他是“坐公交”来的。

------

> [!note]
>
> - **最小错误率决策：** 追求“准”，谁概率大选谁。
> - **最小风险决策：** 追求“稳”，选那个即便错了代价也最小的方案。



## 正态分布下的判别函数

在正态分布（高斯分布）的假设下，贝叶斯决策论的数学表达变得非常具体且直观。我们通过构建判别函数 $g_i(x)$，将分类问题转化为数学计算。

**1. 多维正态分布的基础公式**

如果特征向量 $x$ 是 $d$ 维的，其类条件概率密度函数 $p(x|\omega_i)$ 定义为：

$$p(x|\omega_i) = \frac{1}{(2\pi)^{d/2} |\Sigma_i|^{1/2}} \exp\left[-\frac{1}{2} (x-\mu_i)^T \Sigma_i^{-1} (x-\mu_i)\right]$$

其中：

- **$\mu_i$**：第 $i$ 类的均值向量（代表分布的中心）。
- **$\Sigma_i$**：第 $i$ 类的 $d \times d$ 协方差矩阵（代表分布的形状和方向）。
- **$|\Sigma_i|$**：协方差矩阵的行列式；**$\Sigma_i^{-1}$**：协方差矩阵的逆。

**2. 判别函数的一般形式**

为了方便计算，我们通常对后验概率取对数（不影响单调性）。将正态分布公式代入 $g_i(x) = \ln p(x|\omega_i) + \ln P(\omega_i)$，可以得到通用的判别函数：



$$g_i(x) = -\frac{1}{2}(x-\mu_i)^T \Sigma_i^{-1} (x-\mu_i) - \frac{d}{2}\ln 2\pi - \frac{1}{2}\ln |\Sigma_i| + \ln P(\omega_i)$$



在进行分类对比时，常数项 $\frac{d}{2}\ln 2\pi$ 对所有类别都一样，可以直接忽略。

**3. 情况一：协方差矩阵相等且为缩放单位阵 ($\Sigma_i = \sigma^2 I$)**

这是最简单的情况，假设所有特征之间相互独立，且波动程度（方差）完全相同。

- **物理意义**：每一类数据在空间中都呈正圆球状分布。
- **判定逻辑**：判别函数简化为线性函数。如果先验概率相等，分类决策本质上就是计算点 $x$ 到各个类中心 $\mu_i$ 的**欧氏距离**。
- **决策边界**：不同类别的分界线是**线性超平面**，且垂直平分均值点的连线（当先验相等时）。

**4. 情况二：协方差矩阵相等但为任意阵 ($\Sigma_i = \Sigma$)**

假设所有类别的分布形状完全一样，但它们可以是倾斜的、扁平的椭球体。

- **物理意义**：各类别在空间中的“胖瘦”和“倾斜角度”一致。
- **判定逻辑**：判别函数依然是线性的。此时测量的是点 $x$ 到均值中心的**马氏距离（Mahalanobis Distance）**。马氏距离考虑了特征间的相关性（比如鱼的长和宽通常正相关）。
- **决策边界**：依然是**线性超平面**。这就是经典的线性判别分析（LDA）的数学基础。

**5. 情况三：协方差矩阵为任意值 ($\Sigma_i$ 为任意阵)**

这是最复杂也最一般的情况，每个类别都有自己独特的均值和协方差。

- **物理意义**：有的类是圆的，有的是扁的，有的斜着长。
- **判定逻辑**：判别函数是一个二次项，包含了 $x^T W_i x$ 这样的项。
- **决策边界**：分界线不再是平直的，而是**二次曲面**（如抛物线、圆弧、双曲线等）。这被称为二次判别分析（QDA）。

> [!error] 这块我也没看懂
>
> 应该不考这么难，，，主要概率论为什么不教多维高斯分布呢？要回去补补了

---

## 参数估计

在机器学习中，当我们假设了数据的概率模型（如正态分布）但不知道其具体参数（如均值 $\mu$ 或协方差 $\Sigma$）时，就需要通过**参数估计（Parameter Estimation）**来从训练样本中推导这些数值。这是设计最优分类器的关键步骤。

根据之前提到的概率论流派，参数估计也相应地分为两个核心方向：

**1. 频率派：极大似然估计 (Maximum-Likelihood Estimation, MLE)**

**核心哲学**：认为参数 $\theta$ 是一个固定但未知的常数。

**目标**：寻找能够使观测到的样本出现的概率（似然度）达到最大的参数值。

**数学实现**：

- 我们定义似然函数 $p(D|\theta)$，为了计算方便，通常使用其对数形式，即**对数似然函数** $l(\theta) = \sum \ln p(x_k|\theta)$。
- 通过对该函数求梯度并令其为零来解出最优参数 $\theta^*$。

**直观例子**：在正态分布且均值未知的情况下，MLE 估计出的均值恰好就是所有训练样本的**算术平均值**。

**特点**：计算相对简单，且当样本量足够大时，估计出的参数会非常接近真实值。其收敛特性良好，随着样本数增加，估计值会趋向于真实值。

**2. 贝叶斯派：贝叶斯估计 (Bayesian Estimation)**

**核心哲学**：认为参数 $\theta$ 本身就是一个随机变量，服从某种概率分布。

**工作逻辑：贝叶斯学习 (Bayesian Learning)**：

- **先验知识**：在看到数据之前，我们对参数有一个初始的认知，即先验密度 $p(\theta)$。
- **后验更新**：观测到数据 $D$ 后，利用贝叶斯公式将先验转化为后验密度 $p(\theta|D)$。
- **综合预测**：在实际进行分类时，我们不是直接使用一个最优参数，而是对所有可能的参数进行加权平均（积分），计算类条件概率密度 $p(x|D) = \int p(x|\theta) p(\theta|D) d\theta$。

**特点**：能够将领域专家的经验（先验知识）引入模型。在数据量较少时，由于它利用了先验信息，通常比 MLE 更加稳健。

**3. 两者的关系与对比**

- **计算复杂度**：MLE 通常涉及的是优化问题（找最大值），计算较快；而贝叶斯估计涉及复杂的积分运算，通常需要数值模拟方法（如蒙特卡洛模拟）。
- **处理方式**：MLE 旨在寻找“最优”的一个参数点，而贝叶斯估计则是在维护整个参数的“分布”。
- **收敛性**：随着样本数量的增加，后验分布会变得越来越尖锐，最终两种方法得到的结果在实际预测中会非常接近。
- **应用场景**：如果你有强烈的先验信息，或者数据量非常小，贝叶斯估计更有优势；如果你追求计算效率且样本量充足，MLE 是首选。



---

## 朴素贝叶斯分类器

**朴素贝叶斯分类器（Naïve Bayes Classifier）** 是贝叶斯决策论在实际应用中最流行的简化版本。它在计算上非常高效，尤其适用于文本分类、垃圾邮件过滤等高维数据场景。

**核心假设：特征独立性**

朴素贝叶斯之所以被称为“朴素（Naïve）”，是因为它做了一个极强的假设：给定类别的条件下，所有特征之间相互独立。

- **数学表达**：$P(x_1, x_2, \dots, x_p | \omega) = P(x_1 | \omega) P(x_2 | \omega) \dots P(x_p | \omega)$。
- **为什么要这样做**：在一般情况下，计算多个特征的联合概率分布需要极大的数据量。通过这个独立性假设，我们将复杂的联合概率计算转化成了多个简单的一元概率相乘，极大降低了计算难度。
- 分类目标

我们的目标是找到让后验概率 $P(\omega | x_1, \dots, x_p)$ 最大化的类别 $\omega$。根据贝叶斯定理和独立性假设，判定准则转化为：

$$\text{Decide } \omega \text{ that maximizes } P(\omega) \prod_{i=1}^{p} P(x_i | \omega)$$

其中：

- $P(\omega)$ 是类别的先验概率。
- $P(x_i | \omega)$ 是每个特征在给定类别下的条件概率。
- 如何从数据中估计概率

针对不同类型的属性，估计 $P(x_i | \omega)$ 的方法不同：

- **离散属性**：直接计算频率。例如：$P(\text{状态=已婚} | \text{不拖欠债务}) = \frac{\text{不拖欠债务且已婚的人数}}{\text{不拖欠债务的总人数}}$。
- **连续属性**：通常假设特征服从正态分布。利用之前提到的参数估计（MLE）算出该类别下该特征的均值 $\mu$ 和方差 $\sigma^2$，然后代入正态分布公式求出概率密度值。
- 零概率问题与拉普拉斯平滑（Laplace Smoothing）

在实际训练中，如果某个特征值在某个类别下从未出现过，那么 $P(x_i | \omega) = 0$。由于公式中是连乘关系，这一个零会导致整体结果直接变为 0，从而抹杀了其他所有特征提供的有用信息。

- **解决方案**：在计算概率时进行平滑处理。
- **计算公式**：$P(x_i | \omega_k) = \frac{x_{ik} + 1}{N_{\omega_k} + K}$。
  - 其中 $x_{ik}$ 是出现的次数，$N_{\omega_k}$ 是该类的样本总数，$K$ 是该特征可能取值的个数。这样确保了即使没出现过，概率也只是一个很小的正数。

---

**优点**：

- **鲁棒性强**：对孤立的噪声点不敏感。
- **处理缺失值**：如果某个特征缺失，计算时直接忽略该项即可。
- **效率极高**：训练和预测的计算量都很小，适合大规模数据。

**缺点**：

- **假设过于理想**：在现实中特征往往是相关的（比如鱼的长度和重量通常相关）。如果特征间相关性极强，朴素贝叶斯的表现会下降。

---

举一个贴近生活的例子：**“根据天气特征判断是否去打网球”**。

**建立训练数据集（历史经验）**

假设我们过去 10 天的数据记录如下（标签为：是否打球）：

| **天气 (Outlook)** | **气温 (Temp)** | **打球 (Play?)** |
| ------------------ | --------------- | ---------------- |
| 晴天 (Sunny)       | 高 (Hot)        | 否 (No)          |
| 晴天 (Sunny)       | 高 (Hot)        | 否 (No)          |
| 阴天 (Overcast)    | 高 (Hot)        | 是 (Yes)         |
| 雨天 (Rainy)       | 适中 (Mild)     | 是 (Yes)         |
| 雨天 (Rainy)       | 低 (Cool)       | 是 (Yes)         |
| 雨天 (Rainy)       | 低 (Cool)       | 否 (No)          |
| 阴天 (Overcast)    | 低 (Cool)       | 是 (Yes)         |
| 晴天 (Sunny)       | 适中 (Mild)     | 否 (No)          |
| 晴天 (Sunny)       | 低 (Cool)       | 是 (Yes)         |
| 雨天 (Rainy)       | 适中 (Mild)     | 是 (Yes)         |

------

**统计基本概率（学习阶段）**

根据朴素贝叶斯的逻辑，我们先统计出各个部分的概率：

**先验概率 (Prior)：**

- $P(Yes) = 6/10 = 0.6$ 
- $P(No) = 4/10 = 0.4$ 

**条件概率 (Likelihood)：**

**天气特征：**

- $P(Sunny | Yes) = 1/6 \approx 0.17$
- $P(Sunny | No) = 3/4 = 0.75$

**气温特征：**

- $P(Cool | Yes) = 3/6 = 0.5$
- $P(Cool | No) = 1/4 = 0.25$

------

**进行预测（决策阶段）**

**今天的天气特征：晴天 (Sunny) 且 气温低 (Cool)**，我们要判断去不去打球。

**步骤一：计算“去打球”的得分（分子部分）**

- 公式：$P(Sunny | Yes) \times P(Cool | Yes) \times P(Yes)$ 
- 计算：$0.17 \times 0.5 \times 0.6 = \mathbf{0.051}$

**步骤二：计算“不打球”的得分（分子部分）**

- 公式：$P(Sunny | No) \times P(Cool | No) \times P(No)$ 
- 计算：$0.75 \times 0.25 \times 0.4 = \mathbf{0.075}$

------

**最终决策**

比较两者的得分：

- $0.075 (不打) > 0.051 (打)$ 

**结论：** 朴素贝叶斯分类器建议你**不要去打球**。

---

> [!note]
>
> 为什么叫“朴素”？
>
> 在这个例子中，分类器假设“天气”和“气温”是**互相独立的** 。但现实中，晴天往往伴随着高温，雨天往往伴随着低温。朴素贝叶斯通过忽略这种相关性，把复杂的联合概率变成了简单的乘法，这就是它“朴素”的地方。



