# 机器学习

第一章总览，介绍一点基础概念吧。大的分类是监督学习（带标签），非监督学习（聚类），还有强化学习

机器学习的一个重点是提取特征，比如一条鱼的长度，宽度之类，或者是长度宽度的聚合（相乘等），通过提取的特征因子来训练一个分类器。训练的数学依据就是概率论



## 监督学习

可以把监督学习想象成一个有老师辅导的学生：老师给学生一堆练习题（特征），并且每道题都附带了正确答案（标签）。学生的任务就是通过这些题目，总结出从“题目”推导出“答案”的逻辑。

**监督学习的基本构成**

在监督学习中，数据集通常由成对的 **(特征, 标签)** 组成：

- **特征 (Feature, $x$)：** 描述事物的属性。比如你提到的鱼的长度、宽度、重量。
- **标签 (Label / Target, $y$)：** 我们想要预测的目标。比如这条鱼是“鲈鱼”还是“三文鱼”。
- **模型 (Model, $f$)：** 学习到的规律，数学上表示为 $y = f(x)$。

---

**监督学习的两大任务**

根据标签 $y$ 的类型不同，监督学习主要分为两大类：

A. 分类 (Classification)

- **标签类型：** 离散的标签（类别）。
- **目标：** 预测事物属于哪一类。
- **例子：** * **二分类：** 垃圾邮件识别（是/否）、肿瘤判断（良性/恶性）。
  - **多分类：** 手写数字识别（0-9）、鱼的种类识别。

B. 回归 (Regression)

- **标签类型：** 连续的数值。
- **目标：** 预测一个具体的数值。
- **例子：** * 预测明天的气温（如 23.5°C）。
  - 根据房屋面积、地段预测房价。
  - 根据鱼的长度预测它的重量。

------

### 监督学习的工作流程 (Pipeline)

1. **数据采集：** 收集大量带有标签的数据（如：1000条鱼的数据及其对应的种类）。
2. **特征工程：** 提取有用的特征（如：长宽比可能比单纯的长度更有区分度）。
3. **模型训练：** 将数据输入算法，利用**概率论**（似然派或贝叶斯派的方法）来调整模型参数，减小预测误差。
4. **模型评估：** 用没见过的数据（测试集）来检验模型准不准。
5. **推理预测：** 投入使用，输入一条新鱼的特征，让模型告诉你它是什么鱼。

------

> [!note]
>
> 在监督学习中，有一句名言："Garbage in, Garbage out" (垃圾入，垃圾出)。
>
> 如果你的标签打错了（比如把鲈鱼标注成了三文鱼），或者特征选错了（比如用鱼的颜色预测它的出生日期），模型再强大也学不到正确的规律。



## 非监督学习

**核心定义**

如果说监督学习是“有老师教”，那么非监督学习就是“自学”。你手里有一大堆数据（特征 $x$），但是没有标签 ($y$)。模型并不知道这些数据代表什么，它的目标是发现数据中潜藏的结构、规律或聚集模式。

---

**主要任务：聚类 (Clustering)**

这是非监督学习最常见的形式。模型会根据特征之间的相似性，把数据点自动分成几个簇。

**逻辑：** 物以类聚。虽然模型不知道这群鱼分别叫什么，但它能发现有一群鱼普遍很长，而另一群鱼普遍很圆。

- **客户细分：** 银行根据消费习惯把客户分成“高消费人群”、“保守储蓄人群”，无需人工标注。
- **图像分割：** 自动识别照片中的背景、天空和主体。

**主要任务：降维 (Dimensionality Reduction)**

当你提取的特征太多（比如一条鱼有50个维度的指标），其中很多信息是冗余或不重要的，降维能帮你精简特征。

**逻辑：** 剔除干扰项，只保留最核心的“灵魂特征”。

**PCA (主成分分析)：** 将高维数据投影到低维空间，方便可视化和后续计算。

**主要任务：关联规则学习 (Association Rule Learning)**

发现不同变量之间的“潜在勾连”。

**超市篮子分析：** 经典的“尿布与啤酒”案例。模型发现买尿布的人往往也会买啤酒，这种关联不是靠标签告诉模型的，而是从海量交易记录中自动挖掘出来的。

------

**监督学习 vs 非监督学习 的直观对比**

- **输入：** 监督学习输入 (特征 + 标签)；非监督学习只输入 (特征)。
- **目的：** 监督学习是为了“预测”和“分类”；非监督学习是为了“探索”和“发现”。
- **反馈：** 监督学习有明确的对错衡量标准（误差）；非监督学习的评估通常比较主观，因为它没有所谓的“标准答案”。

------

> [!note]
>
> 在非监督学习中，特征工程更加关键。因为没有标签指路，模型完全依赖特征之间的数学距离（如欧氏距离）来判断它们是不是“一类人”。如果特征选得不好，模型可能就会在无关紧要的属性上把数据分错类。



## 强化学习



如果说监督学习是“老师教书”，非监督学习是“自我总结”，那么强化学习就像是**“训练宠物”**或者**“小孩子学走路”**。

**核心定义**

强化学习不依赖于静态的数据集，而是让一个智能体 (Agent) 在一个环境 (Environment) 中通过不断的尝试与错误 (Trial and Error) 来学习。它没有明确的“正确标签”，只有环境给出的奖励 (Reward) 或惩罚。

**强化学习的五大要素**

可以用这五个词来构建它的逻辑框架：

1. **智能体 (Agent)：** 学习者、决策者（比如 AlphaGo，或者自动驾驶汽车）。
2. **环境 (Environment)：** 智能体所处的世界。
3. **状态 (State)：** 智能体当前感知到的情况（比如棋盘的局势，或者车前方有障碍物）。
4. **动作 (Action)：** 智能体做出的反应（比如落下一子，或者踩下刹车）。
5. **奖励 (Reward)：** 环境对动作的反馈。做对了给正分（赢球、加分），做错了给负分（撞车、扣分）。

![image-20260104184132770](./assets/image-20260104184132770.png)

有兴趣可以看看我在模型后训练中的[RLHF 基于人类反馈的强化学习](../docs/PostTraining/RLHF.md)

**核心逻辑：目标最大化**

智能体的目标不是完成单次动作的正确，而是为了获得长期累积奖励的最大化。

- **延迟满足：** 有时候为了最后的胜利，智能体需要接受眼前的低分（比如下棋时的弃子战术）。这就是强化学习和监督学习最大的区别：动作的效果往往是延迟显现的。

**实际应用举例**

- **游戏领域：** AlphaGo 通过与自己下棋（强化学习）战胜了人类冠军。
- **机器人控制：** 机械臂学习如何精准地抓取不规则形状的物体。
- **推荐系统：** 算法根据你点击或关闭广告的反馈，不断调整推送策略，以增加你的留存时间。



做一个横向对比：

- **监督学习：** 学习“映射关系”（特征 $\rightarrow$ 标签）。
- **非监督学习：** 学习“内在结构”（特征 $\rightarrow$ 聚类/规律）。
- **强化学习：** 学习“行为准则”（状态 $\rightarrow$ 动作，以获得最大奖励）。

------

> [!note]
>
> 在强化学习中，概率论同样重要。比如，智能体在某个状态下采取某个动作的概率，我们称之为策略 (Policy)。通过数学优化，我们要找到那个能让得分概率最高的最佳策略。





## 特征提取

**特征提取 (Feature Extraction)** 是衔接“现实世界”与“数学模型”的桥梁。模型看不见“鱼”，它只能看见代表鱼的一串数字。

**核心定义**

特征提取是将原始数据（Raw Data）转换为一组能够代表其关键特性的、可用于机器学习算法输入的数值（特征向量）的过程。正如你所说，如果原始数据是一张鱼的照片，特征就是我们手动或自动提取出的长度、宽度、鳞片密度等指标。

**为什么需要特征提取？**

- **降维：** 原始数据可能非常庞大（比如一张高清照片有数百万个像素），提取特征可以剔除无关信息，只保留对分类有用的核心信息。
- **增强鲁棒性：** 原始数据容易受噪声干扰，而经过计算的特征（如长宽比）往往比原始长度更稳定。
- **提升模型效率：** 特征越精准，算法训练的速度就越快，需要的计算资源也越少。

**特征提取的常见方式**

- 物理特征（直接测量）：

  鱼的长度、宽度、重量、背鳍数量。

- 聚合特征（数学组合）：

  通过数学运算将多个原始特征组合在一起，往往能捕捉到更深层的逻辑。

  例子：长宽比 (Length / Width)。这个特征可能比单一的长度更能区分“带鱼”（长且窄）和“鲳鱼”（短且宽）。

- 统计特征：

  对于一组数据（如一段音频或一段气温记录），提取其统计学指标。

  例子：平均值、方差、最大值、最小值、中位数。

- 结构/纹理特征：

  在图像处理中常用。

  例子：边缘检测（鱼的轮廓线）、颜色直方图（鱼身的颜色分布）。

- 特征向量与特征空间

当你提取了多个特征（比如：长度 $x_1$, 宽度 $x_2$），这些特征就会组成一个特征向量 $X = [x_1, x_2]$。

- 每个样本（每条鱼）都可以看作是多维空间中的一个**点**。
- 这个空间就叫**特征空间**。
- 分类器的本质，就是在特征空间里画出一条“边界线”，把代表不同类别的点隔开。
- 特征提取与概率论的联系

你在开头提到的概率论在这里起到了决定性作用。我们要寻找的是那些区分度最高的特征。

- 从概率的角度看，我们要找的是特征 $x$，使得在不同类别 $C$ 下的条件概率分布 $P(x|C)$ 差异最大。
- 比如，如果“长度”在鲈鱼和三文鱼中出现的概率分布重叠很严重，那么“长度”就是一个差特征；如果重叠很少，它就是一个好特征。

------

> [!note] 手动特征 vs 自动特征
>
> **传统机器学习：** 依赖专家经验手动提取特征（Feature Engineering）。
>
> **深度学习（神经网络）：** 能够自动从原始数据中提取特征，不需要人工干预，这也是深度学习强大的一面。





## 概率论

在统计学和机器学习中，关于如何看待“概率”，主要分为两大阵营：频率派（Frequentist）和贝叶斯派（Bayesian）。

------

 **频率派 (Frequentist)**

频率派的核心工具是**极大似然估计 (Maximum Likelihood Estimation, MLE)**。

- **核心观点：** 参数 $\theta$ 是**客观存在且固定**的实数，只是我们暂时不知道。
- **如何推断：** 既然参数是固定的，那我们就通过不断重复实验，看数据分布。如果这组数据在某个参数 $\theta$ 下出现的概率最大，那这个 $\theta$ 就是我们要找的真值。
- **特点：**
  - 强调数据的客观性。
  - 认为数据是随机变量，参数是常数。
- **典型算法：** 逻辑回归、普通的线性回归。

**贝叶斯派 (Bayesian)**

贝叶斯派的核心工具是**贝叶斯公式**，通过**最大后验概率 (Maximum A Posteriori, MAP)** 进行估计。

**核心观点：** 参数 $\theta$ 不是固定的，而是**服从某种概率分布**的随机变量。

**如何推断：** 我们在观察数据之前，先对参数有一个“主观”的猜测，这叫**先验概率 (Prior)**。看到数据后，我们根据数据（似然）来修正之前的猜测，得到**后验概率 (Posterior)**。

核心公式：

$$P(\theta|Data) = \frac{P(Data|\theta) \cdot P(\theta)}{P(Data)}$$

- $P(\theta|Data)$：后验概率（我们想要的）
- $P(Data|\theta)$：似然（数据表现出的样子）
- $P(\theta)$：先验（我们的经验或直觉）

**典型算法：** 朴素贝叶斯、隐马尔可夫模型 (HMM)。