---
comments : true
---



# Chapter5 Cache/Memory

## 1 总览

存储器层次结构（Memory Hierarchy）的设计初衷是为了解决**处理器速度快**与**存储器访问慢**之间的矛盾，也就是常说的“存储墙”问题。其核心思想是利用**局部性原理（Locality of Reference）**，通过构建多层存储空间，在成本、容量和速度之间取得平衡。

------

### 存储器金字塔结构

存储器通常被组织成一个金字塔形，从上到下容量越来越大，速度越来越慢，但单位成本也越来越低：

- **寄存器 (Registers)**：位于 CPU 内部，速度极快（与 CPU 同频），容量极小（通常仅几百字节）。
- **高速缓存 (Cache)**：分为 L1、L2、L3 三级。L1 最快但最小，L3 最慢但容量最大。它存储了 CPU 近期可能访问的数据。
- **主存 (Main Memory/RAM)**：存放当前正在运行的程序和数据。
- **辅存 (Secondary Storage)**：如 SSD 或 HDD，容量巨大且数据掉电不丢失，但访问速度比内存慢数千倍。

------

### 核心原理：局部性原理 (Locality)

存储层次结构之所以有效，是因为程序运行具有以下两个特性：

- **时间局部性 (Temporal Locality)**：如果一个数据被访问了，那么它在不久的将来很可能再次被访问（例如循环中的计数器）。
- **空间局部性 (Spatial Locality)**：如果一个数据被访问了，那么它相邻的数据在不久的将来也很可能被访问（例如遍历数组）。

------

### 关键术语

在学习层次结构时，你会经常遇到以下概念：

- **命中 (Hit)**：CPU 所需的数据在较高级别（较快）的存储器中找到。
- **缺失 (Miss)**：在较快存储器中找不到数据，必须向下一级索取。
- **命中率 (Hit Rate)**：命中次数占总访问次数的比例。
- **缺失惩罚 (Miss Penalty)**：处理一次缺失所需额外消耗的时间（通常包括将数据从低速层搬运到高速层的时间）。

------

### 存储层级间的数据传输

数据在不同层级之间是以固定大小的块（Block/Line）为单位传输的。

- **Cache 与内存之间**：传输单位通常是 **Cache Line**（如 64 字节）。
- **内存与硬盘之间**：传输单位通常是 **页 (Page)**（如 4KB）。

------



## 2 Cache

既然我们已经了解了存储器层次结构的宏观“金字塔”模型，接下来我们需要深入探讨这一体系的核心：**高速缓存（Cache）**。

Cache 的存在是为了在 CPU 和主存之间架起一座桥梁。它利用**局部性原理**，将 CPU 最近可能用到的数据从慢速的主存搬运到快速的 Cache 中。

------

### Cache 的基本操作逻辑

当 CPU 需要访问一个地址时：

1. **命中 (Hit)**：数据已在 Cache 中。CPU 以极快速度读取。
2. **缺失 (Miss)**：数据不在 Cache 中。CPU 必须等待，从主存中将包含该数据的整个**块（Block/Line）**搬运到 Cache 中，然后再读取。

------

**地址映射（Mapping）**

内存很大（GB级别），Cache 很小（MB级别）。如何决定内存中的某个数据存放在 Cache 的哪个位置？主要有三种映射方案：直接映射，全相联映射，组相联映射。

A. 直接映射 (Direct Mapped)

- **规则**：内存中的每个块只能存放在 Cache 中**唯一**确定的位置。
- **计算**：通常使用 `(块地址 % Cache块数)`。
- **优缺点**：硬件设计最简单，成本低；但容易发生**碰撞（Conflict Miss）**，如果两个经常使用的块映射到同一个位置，它们会互相踢出。

B. 全相联映射 (Fully Associative)

- **规则**：内存块可以存放在 Cache 的**任何**空闲位置。
- **优缺点**：空间利用率最高，碰撞概率最低；但硬件搜索极慢且昂贵，因为 CPU 必须同时检查 Cache 中的所有位置。

C. 组相联映射 (Set Associative)

- **规则**：这是前两者的折中方案。将 Cache 分成若干“组”，块映射到固定的组，但在组内可以存放在任何位置（例如“2路组相联”表示每组有两个位置）。
- **现状**：这是目前主流 CPU（如 Intel、AMD、ARM）最常用的方案。



## 3 直接映射 (Direct Mapped)

**直接映射 (Direct Mapped Cache)** 是最简单的一种映射方式。它的核心思想是：内存中的每一个块（Block）在 Cache 中都有一个**固定且唯一**的对应位置。

你可以把它想象成“按门牌号入座”：内存空间被分成了很多个小组，每个小组的成员只能去 Cache 里的那个特定位置。

------

### **映射规则：取模运算**

内存地址到 Cache 位置的对应关系通常通过**取模（Modulo）**运算来实现：

$$Cache 索引 = (内存块地址) \mod (Cache 中的总块数)$$

例如，如果你的 Cache 有 8 个槽位（Index 0-7）：

- 内存第 0 块、第 8 块、第 16 块... 都会映射到 **Cache Index 0**。
- 内存第 1 块、第 9 块、第 17 块... 都会映射到 **Cache Index 1**。

#### 示例一：单字节block

![image-20260102002046241](./assets/image-20260102002046241.png)

以这个cs61c的示例图为例，此时cache中一共有4个block，每个block大小为1字节。将内存按照block大小分块，然后对4取余，那么余数为0的就到index为0的缓存块中。从颜色可以直观的看出这个映射规律。



#### 示例二：多字节block

![image-20260102002623533](./assets/image-20260102002623533.png)

在这个例子中，一个block的大小增大到2字节，也就是cache中的一行。但是我们依然可以将内存按照block大小分块，然后对应取余。

这个时候有两个问题：

1. 当我请求一个block中的一个字节时，我会取来一个字节还是这一整个block（一整行）？
2. 当我请求一个block中的字节时，我怎么知道他在这一行的哪个位置？

对于第一个问题：前面的基本操作逻辑已经提到了，我们会取来这一整个block。这是空间局部性原理导致的，如果一个数据块被访问了，那么他相邻的数据块很有可能也会被访问到。而我们去内存取一次数据的开销是十分昂贵的。去cache取数据就像去书桌上拿一本书，而去内存取一次数据就像开车到市中心图书馆取书。此时如果你说我想读一本关于计算机系统原理的书，你就会顺手带两本和他相关的书，避免下一次要再开车来一次。

对于第二个问题，这就引出了我们在cache中是如何给字节标定地址的。

---

### 地址的拆分

为了在 Cache 中快速找到数据并确认它是不是我们要的那一个，CPU 会将 32 位（或 64 位）的内存地址拆解为三个部分：

- **标记 (Tag)**：地址的高位部分。它用来区分映射到同一个 Cache Index 的不同内存块。
- **索引 (Index)**：中间部分。用来确定数据应该存放在 Cache 的哪一行（Row）。
- **块偏移 (Block Offset)**：低位部分。用来确定数据在某一个 Cache 块内的具体字节位置。

![image-20260102005633475](./assets/image-20260102005633475.png)

> [!example]
>
> ![image-20260102003717613](./assets/image-20260102003717613.png)
>
> 这个图演示了Tag是如何确定的，将内存按照Cache的大小分组，我们需要知道这个block是哪个组的block。



> [!example]
>
> ![image-20260102003854521](./assets/image-20260102003854521.png)
>
> 这个图演示了Cache中的具体布局，想要计算一个cache到底能存多少字节的数据，就要知道包含多少个block(Height)，一个block（一行）包含多少字节(Width)



#### 示例三：Cache 寻址

![image-20260102004143637](./assets/image-20260102004143637.png)

以这个图为例，Cache中一个Tag = 0, Index = 0, offset = 0 的字节，对应内存第一个分组，行数为0，offset = 0，也就是从第一行右起第一个位置的字节。offset + 1时，向左移一个字节。

------

### 直接映射的内部结构

每一个 Cache 槽位（Entry）由三部分组成：

1. **有效位 (Valid Bit)**：标记该位置是否有有效数据（1表示有，0表示为空或无效）。
2. **标记 (Tag)**：存储该位置当前存放的内存块的高位地址。
3. **数据 (Data)**：存储从内存搬运过来的实际数据块。

#### 示例四：包含有效位的寻址

![image-20260102005942772](./assets/image-20260102005942772.png)

根据地址我们可以找到字节在Cache中对应的位置，但是事实是，在找到对应Index之后，我们要做的第一件事不是对比Tag是否一致，而是判断有效位是否为1。如果一个Cache刚被启用，那么所有的数据都是空的，有效位都置0，里面都是垃圾，这时候我们可以说这个cache是“冷的”。

---

### 直接映射的硬件结构

![image-20260102010332873](./assets/image-20260102010332873.png)

------

### 优缺点分析

- **优点**：
  - **硬件极其简单**：不需要复杂的查找电路，只需要一个比较器检查 Tag 是否匹配即可。
  - **访问速度快**：因为位置是唯一的，CPU 可以直接跳到目标位置。
  - **成本低**：逻辑门数量少。
- **缺点（碰撞问题）**：
  - **冲突缺失 (Conflict Miss)**：这是它的致命伤。如果程序频繁地在内存第 0 块和第 8 块之间切换（它们都映射到 Index 0），Cache 就会不断地发生“踢出-搬运-再踢出”的循环，这被称为 **Cache 抖动 (Thrashing)**。

------

### 写策略

当 CPU 修改了 L1 Cache 中的数据时，主存（Main Memory）里的对应数据就会变得“过期”。如何同步这些修改，主要有两种策略：**写穿透**和**写回**。

------

**写穿透 (Write-Through)**

这是最保守、最简单的做法。

- **操作逻辑**：每次 CPU 往 Cache 里写数据时，数据会**同时**被写入 Cache 和下一级存储（如主存）。
- **优点**：
  - **数据一致性好**：主存里的数据永远是最新的，维护起来非常简单。
  - **实现简单**：发生缺失（Miss）时不需要考虑复杂的写回逻辑。
- **缺点**：
  - **效率极低**：由于内存速度比 CPU 慢百倍，每次写操作都要等内存确认，CPU 会被严重拖慢。
- **优化：写缓冲 (Write Buffer)**：为了缓解速度差，通常会在 CPU 和内存间加一个“小推车”（Buffer）。CPU 把数据扔进缓冲就走，由缓冲慢慢写往内存。

------

**写回 (Write-Back)**

这是现代高性能 CPU（如 Intel、AMD、ARM）普遍采用的方案。

- **操作逻辑**：CPU 修改数据时，**只更新 Cache**，并不立刻写回主存。
- **脏位 (Dirty Bit)**：为了记住哪些数据被改过，Cache 每一行会多加一个 `Dirty bit`。
  - 如果该块被修改过，`Dirty bit` 设为 1。
  - 如果没被修改过，`Dirty bit` 为 0。
- **触发写回**：只有当这个“脏块”因为要给新数据腾位置而被**踢出 (Evict)** 时，硬件才会检查 `Dirty bit` 并将其内容写回主存。
- **优点**：
  - **性能极高**：绝大多数写操作都在极快的 Cache 中完成，大大减少了对总线和内存的占用。
- **缺点**：
  - **逻辑复杂**：需要处理脏位检测和踢出时的写回动作。

------

**写缺失 (Write Miss) 的处理**

如果 CPU 想写一个数据，但它不在 Cache 里，该怎么办？

1. **写分配 (Write Allocate)**：把数据从内存取到 Cache 里，然后再写。通常搭配**写回**策略。
2. **非写分配 (No Write Allocate)**：直接在内存里写，不进 Cache。通常搭配**写穿透**策略。

------

### 性能评价标准

存储器层次结构的好坏主要由 平均访存时间 (AMAT) 决定：

$$AMAT = \text{命中时间} + (\text{缺失率} \times \text{缺失惩罚})$$

- 命中时间 (Hit Time)：

  当数据就在当前层级（如 L1 Cache）时，读取它所需的时间。这通常非常短（例如 1~2 个时钟周期）。

- 缺失率 (Miss Rate)：

  CPU 访问当前层级却找不到所需数据的概率（即 $1 - \text{命中率}$）。

- 缺失惩罚 (Miss Penalty)：

  一旦发生缺失，CPU 为了从更低一级存储（如主存）获取数据并搬运回高速缓存所付出的额外代价。

---

## 4 组关联映射

组相联映射（Set Associative Mapping）是存储器设计中的一种折中方案，它巧妙地结合了直接映射的低成本/高速度与全相联映射的高灵活性/低缺失率。在主流 CPU 中，这是最常采用的 Cache 映射方式。

------

### 基本结构：组 (Set) 与 路 (Way)

组相联将 Cache 划分为若干个“组”（Set），每一组内包含固定数量的“位置”（槽位），每个位置被称为一个“路”（Way）。

- **N 路组相联 (N-way Set Associative)**：意味着每一组里有 $N$ 个槽位。
- **映射规则**：内存中的一个块（Block）根据地址映射到一个**固定的组**，但在该组内部，它可以存放在 **$N$ 个路中的任何一个**位置。

> **比喻**：直接映射就像是“对号入座”的电影院（每人只能坐一个指定座）；组相联就像是“包厢制”餐厅（你被分配到 3 号包厢，但包厢里的 4 把椅子你可以随便挑一把坐）。

#### 示例五：组关联映射

![image-20260102011427103](./assets/image-20260102011427103.png)

在这个红配绿赛狗史的图中，我们可以理解，就是按照取余分组之后，内存中同一个余数可以对应不同的index了。

这解决了抖动的问题，也就是说，假如我在循环中需要反复把A的值赋给B，而AB恰好在不同组，但是余数相同的块（也就是说在两个不同的绿块中），如果是直接映射，先取A再取B的操作必然会导致缓存中的冲突，一个循环内至少要去内存取一次A，发生冲突再去一次B，造成了严重的时间惩罚，但是只要有两个位置的组关联映射就能完美解决这个问题。

------

### 地址的拆分

与直接映射类似，32 位地址被拆分为三个部分，但由于结构的改变，位数的分配发生了变化：

- **索引 (Index)**：用于定位数据属于哪一个“组”。
- **标记 (Tag)**：用于在选定的组内，通过并行比对来确认哪一路存放的是目标数据。
- **偏移 (Offset)**：用于在块内定位具体的字节。

------

### 工作原理：并行比对

当 CPU 访问组相联 Cache 时，会发生以下动作：

1. **定位组**：根据 **Index** 找到对应的组。
2. **并行比对**：将地址中的 **Tag** 同时发送给该组内的**所有路**。
3. **判定命中**：如果某一路的 **Tag 匹配** 且 **有效位 (Valid bit)** 为 1，则 Cache 命中。

![image-20260102011916903](./assets/image-20260102011916903.png)

------

> [!note]
>
> 为什么组相联更好？（解决“抖动”问题）
>
> 组相联最大的优势是极大地缓解了**冲突缺失 (Conflict Miss)**。
>
> - **直接映射的弱点**：如果两个频繁使用的内存块映射到同一个 Index，它们会不停地互相踢出（Cache 抖动）。
> - **组相联的解法**：在组相联中，这两个块可以同时存在于同一个组的不同“路”中，互不干扰。实验表明，**2路或4路组相联**就能消除大部分的冲突缺失。

------

### 替换算法 (Replacement Policy)

由于一组内有多个位置，当组满了又要搬进新数据时，硬件必须决定“踢走谁”。常用的算法包括：

- **LRU (Least Recently Used)**：踢走最久没被访问过的那一个。
- **Random**：随机踢走一个（简单但有效）。

------



